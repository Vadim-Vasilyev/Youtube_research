{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc78ba4-5464-4a5f-b000-f00030317aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e59b8da6-3f2e-49d8-8e6f-4b84ab2727fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ParserDB import ParserDB\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "with open(\"./data/data_json/openai_token.txt\", \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37d886b0-fb01-44ab-a514-24e32bcbdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai structuded output\n",
    "request_format = {\n",
    "    \"format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"name\": \"user_stances_batch\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"threads\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"threadId\": {\"type\": \"string\"},\n",
    "                            \"users\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"user\": {\"type\": \"string\"},\n",
    "                                        \"stance\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"enum\": [\"поддерживает\", \"не поддерживает\", \"невозможно сказать\"]\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"user\", \"stance\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"threadId\", \"users\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"threads\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# prompts for GPT-model\n",
    "request_text_chemtrails =\\\n",
    "\"\"\"Тебе дано 10 тредов комментариев на ютубе. \\\n",
    "Пользователи под видеороликами спорят о конспирологической теории химтрейлов, \\\n",
    "то есть о распылении химикатов самолётами. Противники теории считают, что это инверсионный след, а не химикаты. \\\n",
    "Ты должен для каждого пользователя каждого треда определить, поддерживает он теорию о химтрейлах, не поддерживает, \\\n",
    "или невозможно определить. Формат данных: @пользователь: текст комментария. Если в тексте комментария есть @@username, \\\n",
    "значит автор комментария отвечает какому-то юзеру. Для каждого пользователя каждого треда определи, \\\n",
    "поддерживает он теорию о химтрейлах, не поддерживает, или невозможно определить.\\\n",
    "В ответе имена пользователей начинай записывать с @, так же, как в тексте треда. \\\n",
    "Для каждого треда определяй независимо.\"\"\"\n",
    "\n",
    "request_text_newchron =\\\n",
    "\"\"\"Тебе дано 10 тредов комментариев на ютубе. \\\n",
    "Пользователи под видеороликами спорят о конспирологической теории \"Новой хронологии\" Фоменко. \\\n",
    "Это такая псевдонаучная программа пересмотра истории, оппонирующая \"официальной истории\". \\\n",
    "Ты должен для каждого пользователя каждого треда определить, поддерживает он новую хронологию, не поддерживает, \\\n",
    "или невозможно определить. Формат данных: @пользователь: текст комментария. Если в тексте комментария есть @@username, \\\n",
    "значит автор комментария отвечает какому-то юзеру. Для каждого пользователя каждого треда определи, \\\n",
    "поддерживает он новую хронологию, не поддерживает, или невозможно определить. \\\n",
    "В ответе имена пользователей начинай записывать с @, так же, как в тексте треда. \\\n",
    "Для каждого треда определяй независимо.\"\"\"\n",
    "\n",
    "request_text_flatearth =\\\n",
    "\"\"\"Тебе дано 10 тредов комментариев на ютубе. \\\n",
    "Пользователи под видеороликами спорят о конспирологической теории плоской Земли. \\\n",
    "Сторонники теории считают, что планета Земля является плоской/вогнутой/какой-то ещё, а не шарообразной, и спорят с \"официальной наукой\". \\\n",
    "Ты должен для каждого пользователя каждого треда определить, поддерживает он теорию плоской земли, не поддерживает, \\\n",
    "или невозможно определить. Формат данных: @пользователь: текст комментария. Если в тексте комментария есть @@username, \\\n",
    "значит автор комментария отвечает какому-то юзеру. Для каждого пользователя каждого треда определи, \\\n",
    "поддерживает он теорию плоской земли, не поддерживает, или невозможно определить. \\\n",
    "В ответе имена пользователей начинай записывать с @, так же, как в тексте треда. \\\n",
    "Для каждого треда определяй независимо.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c79341b-1c78-4d1c-b6ad-75714613b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ParserDB(api_key_file=\"./data/data_json/api_token.txt\", database=\"./data/data.db\")\n",
    "p.comments_to_csv(\"химтрейлы\", \"./data/comments_chemtrail.csv\")\n",
    "p.comments_to_csv(\"новая хронология\", \"./data/comments_newchron.csv\")\n",
    "p.comments_to_csv(\"теория плоской земли\", \"./data/comments_flatearth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "53edfc06-856a-4c0d-9bd8-efd8436855ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(comments_file, output_folder, prefix, request_text, request_format):\n",
    "    REQUEST_SIZE = 10 # threads in request\n",
    "    BATCH_SIZE = 15000 # requests in batch\n",
    "    \n",
    "    df = pd.read_csv(comments_file)\n",
    "    df = df[df['text'].notna()].sort_values(by=['topLevelComment', 'publishedAt'])\n",
    "    threads = df.groupby(['topLevelComment'])[[\"authorDisplayName\", \"text\"]].apply(\n",
    "        lambda g: '\\n'.join(f\"{row['authorDisplayName']}: {row['text']}\" for _, row in g.iterrows())).reset_index(name='thread')\n",
    "    batches = [threads[i:i+BATCH_SIZE] for i in range(0, len(threads), BATCH_SIZE)]\n",
    "    for i, b in enumerate(batches):\n",
    "        with open(f\"{output_folder}/{prefix}_{i+1}.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "            for request_index in range(0, len(b), REQUEST_SIZE):\n",
    "                chunk = b.iloc[request_index:request_index + REQUEST_SIZE]\n",
    "                combined_text = \"\\n\\n\".join(\n",
    "                    f\"Тред {row['topLevelComment']}:\\n{row['thread']}\" for _, row in chunk.iterrows()\n",
    "                )\n",
    "                request_id = f\"{(BATCH_SIZE // REQUEST_SIZE) * i + request_index // REQUEST_SIZE + 1}\"\n",
    "                \n",
    "                obj = {\n",
    "                    \"custom_id\": request_id,\n",
    "                    \"method\": \"POST\",\n",
    "                    \"url\": \"/v1/responses\",\n",
    "                    \"body\": {\n",
    "                        \"model\": \"gpt-4.1-mini\",\n",
    "                        \"input\": [\n",
    "                            {\"role\": \"system\", \"content\": request_text},\n",
    "                            {\"role\": \"user\", \"content\": combined_text}\n",
    "                        ],\n",
    "                        \"text\": request_format\n",
    "                    }\n",
    "                }\n",
    "                f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e35d83e6-05b2-44da-856b-eb9be927c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def batch_to_api(input_file):\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(input_file, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/responses\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "869ba07c-556c-441e-93a3-95f8158192cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batches(\"./data/comments_chemtrail.csv\", \"./data/openai_batches\", \"batch_chemtrails\", request_text_chemtrails, request_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b6871bf-a7db-4c02-b084-31c1b5aa5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batches(\"./data/comments_newchron.csv\", \"./data/openai_batches\", \"batch_newchron\", request_text_newchron, request_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be5ec710-72b9-4ec9-a9e1-dd3c5f6a92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batches(\"./data/comments_flatearth.csv\", \"./data/openai_batches\", \"batch_flatearth\", request_text_flatearth, request_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a08fcfc4-ea8f-4991-8ec3-44c5083f1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_to_api(\"./data/openai_batches/batch_newchron_1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e349a5d1-4e7a-4149-9a73-0a3ee50a5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stances_by_thread(data):\n",
    "    user_stances = {} # {user: {supports: 3, ...}}\n",
    "    \n",
    "    with open(data, \"r\") as f:\n",
    "        for l in f.readlines():\n",
    "            response_text = json.loads(json.loads(l)[\"response\"][\"body\"][\"output\"][0][\"content\"][0][\"text\"])\n",
    "            for thread in response_text[\"threads\"]:\n",
    "                for user in thread[\"users\"]:\n",
    "                    username = user[\"user\"]\n",
    "                    userstance = user[\"stance\"]\n",
    "                    cur_user_stance = user_stances.get(username, {})\n",
    "                    cur_user_stance[userstance] = cur_user_stance.get(userstance, 0) + 1\n",
    "                    user_stances[username] = cur_user_stance\n",
    "    return user_stances\n",
    "\n",
    "def define_user_stance(stance_counts):\n",
    "    if stance_counts.get(\"поддерживает\", 0) == stance_counts.get(\"не поддерживает\", 0):\n",
    "        return \"невозможно определить\"\n",
    "    return \"поддерживает\" if stance_counts.get(\"поддерживает\", 0) > stance_counts.get(\"не поддерживает\", 0) else \"не поддерживает\"\n",
    "\n",
    "def make_graph(threads_by_videos, user_stances, folder_to_save):\n",
    "    nodes = set()\n",
    "    edges = set()\n",
    "    \n",
    "    reply_count = 0\n",
    "    problem_count = 0\n",
    "    for videoId, videoThreads, query in threads_by_videos:\n",
    "        videoThreads = json.loads(videoThreads)\n",
    "        users = set()\n",
    "        thread_authors = dict() # {topLevelComment: author}\n",
    "        nodes.add((videoId, \"video\", query))\n",
    "        for thread in videoThreads:\n",
    "            thread = json.loads(thread)\n",
    "            for comment in thread:\n",
    "                users.add(comment[\"authorDisplayName\"])\n",
    "                nodes.add((comment[\"authorDisplayName\"], \"user\", \"USER\"))\n",
    "                if comment[\"topLevelComment\"] == comment[\"commentId\"]:\n",
    "                    thread_authors[comment[\"topLevelComment\"]] = comment[\"authorDisplayName\"]\n",
    "                \n",
    "        for thread in videoThreads:\n",
    "            thread = json.loads(thread)\n",
    "            thread_author = thread_authors[thread[0][\"topLevelComment\"]]\n",
    "            for comment in thread:\n",
    "                if comment[\"authorDisplayName\"] == thread_author:\n",
    "                    edges.add((comment[\"authorDisplayName\"], videoId))\n",
    "                elif \"@\" not in comment[\"text\"]:\n",
    "                    edges.add((comment[\"authorDisplayName\"], thread_author))\n",
    "                else:\n",
    "                    reply_to = None\n",
    "                    for user in users:\n",
    "                        if user in comment[\"text\"]:\n",
    "                            reply_to = user\n",
    "                            break\n",
    "                    if reply_to is not None:\n",
    "                        edges.add((comment[\"authorDisplayName\"], reply_to))\n",
    "                    else:\n",
    "                        problem_count += 1\n",
    "\n",
    "    nodes = [dict(id=n[0], label=n[0], nodeType=n[1], query=n[2], stance=define_user_stance(user_stances.get(n[0], {}))) for n in nodes]\n",
    "    edges = [dict(source=e[0], target=e[1]) for e in edges]\n",
    "    \n",
    "    nodes_df = pd.DataFrame(nodes)\n",
    "    nodes_df[\"size\"] = np.where(nodes_df[\"nodeType\"] == \"video\", 20, 1)\n",
    "    nodes_df.to_csv(f\"{folder_to_save}/nodes.csv\", index=False, encoding=\"utf-8\")\n",
    "    pd.DataFrame(edges).to_csv(f\"{folder_to_save}/edges.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4459a295-cd15-4386-9209-19dea42a2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EI-index: (E - I) / (E + I)\n",
    "# E - external connections (responses to opponents); I - internal connections (responses to group-members)\n",
    "def calculate_ei(nodes, edges):\n",
    "    merged = pd.merge(\n",
    "        edges,\n",
    "        nodes.rename(columns={\"label\": \"source\", \"stance\": \"source_stance\"}),\n",
    "        on=\"source\"\n",
    "    )[[\"target\", \"source\", \"source_stance\"]]\n",
    "    merged = pd.merge(\n",
    "        merged,\n",
    "        nodes.rename(columns={\"label\": \"target\", \"stance\": \"target_stance\"}),\n",
    "        on=\"target\"\n",
    "    )[[\"target\", \"source\", \"source_stance\", \"target_stance\"]]\n",
    "    merged = merged[(merged[\"source_stance\"] != \"невозможно определить\") & (merged[\"target_stance\"] != \"невозможно определить\")]\n",
    "    \n",
    "    reply_counts = merged.groupby(by=[\"source_stance\", \"target_stance\"]).size()\n",
    "    \n",
    "    I_support = reply_counts.loc[\"поддерживает\"][\"поддерживает\"]\n",
    "    I_oppose = reply_counts.loc[\"не поддерживает\"][\"не поддерживает\"]\n",
    "    E_support = reply_counts.loc[\"поддерживает\"][\"не поддерживает\"]\n",
    "    E_oppose = reply_counts.loc[\"не поддерживает\"][\"поддерживает\"]\n",
    "\n",
    "    print(I_support, I_oppose, E_support, E_oppose)\n",
    "    \n",
    "    EI_support = (E_support - I_support) / (E_support + I_support)\n",
    "    EI_oppose = (E_oppose - I_oppose) / (E_oppose + I_oppose)\n",
    "    return EI_support, EI_oppose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b181c04-5e94-4259-ab6d-377ae1d95422",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemtrails_threads = p.get_threads(\"химтрейлы\")\n",
    "chemtrails_stances = stances_by_thread(\"./data/openai_responses/batch_chemtrails_output.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64f8ac23-d419-4b45-a524-30aa929ddb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_graph(chemtrails_threads, chemtrails_stances, \"data/gephi_chem_stances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "498d1c4b-dae5-4989-9485-bd870ecb7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemtrails_nodes = pd.read_csv(\"./data/gephi_chem_stances/nodes.csv\")\n",
    "chemtrails_edges = pd.read_csv(\"./data/gephi_chem_stances/edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7cfc24d0-30d8-4cc8-9f7d-9a7dfcd47d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newchron_threads = p.get_threads(\"новая хронология\")\n",
    "newchron_stances = stances_by_thread(\"./data/openai_responses/batch_newchron_1_output.jsonl\")\n",
    "make_graph(newchron_threads, newchron_stances, \"data/gephi_newchron_stances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1a0a89c5-85d1-42c2-915d-c97c7fc8d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "newchron_nodes = pd.read_csv(\"./data/gephi_newchron_stances/nodes.csv\")\n",
    "newchron_edges = pd.read_csv(\"./data/gephi_newchron_stances/edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8d6244a7-8d4d-4284-a442-e5e2bc7b829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909 1030 1236 2450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5977217249796583, 0.40804597701149425)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ei(chemtrails_nodes, chemtrails_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "55542c83-d492-4dc5-9d0e-466983d91a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986 964 728 1306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.15052508751458576, 0.15066079295154186)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ei(newchron_nodes, newchron_edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
